{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d310f01-8cdf-4865-8ca0-aca1ceb11ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANALYSIS OF REVIEW SEMANTICS (<u>PREDICTION MODEL</u>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b2b9d-6525-4b69-b33d-1fc76c4faeed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>1. Preliminaries</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f5892-7aa5-4e2e-9c46-aab970996715",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9deeaea1-af4f-4283-831f-50055ef47f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\PROGRAMOWANIE\\anaconda\\program\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "G:\\PROGRAMOWANIE\\anaconda\\program\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Import necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5c28c-fdc4-4def-bfe3-f9cd75256af7",
   "metadata": {},
   "source": [
    "### 1.2 Version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7e77be-da65-44bc-9365-5b8c2aa8ca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "Keras version: 3.3.3\n",
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.2.2\n",
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "#Check Python version\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'Keras version: {keras.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65aa6d-1d01-40dc-919d-ff1627196437",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>2. Data preperation</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd5385c-ceea-4f48-863a-df3b13545c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALLY PROCESSED DATA TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_score                             review_comment_message\n",
       "3              2              Recebi bem antes do prazo estipulado.\n",
       "4              2  Parabéns lojas lannister adorei comprar pela I...\n",
       "9              2  aparelho eficiente. no site a marca do aparelh...\n",
       "12             2    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "15             2  Vendedor confiável, produto ok e entrega antes..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "df = pd.read_csv(\"data/order_reviews.csv\")\n",
    "\n",
    "#Modify the original dataframe\n",
    "df_model = df.drop(['review_id', 'order_id', 'review_comment_title', 'review_creation_date', 'review_answer_timestamp'], axis=1).dropna()\n",
    "\n",
    "#Define and apply score mapping: 0 - bad, 1 - neutral, 2 - good\n",
    "score_mapping = {1: 0,\n",
    "                 2: 0,\n",
    "                 3: 1,\n",
    "                 4: 2,\n",
    "                 5: 2}\n",
    "\n",
    "df_model['review_score'] = df_model['review_score'].map(score_mapping)\n",
    "\n",
    "print('\\nINITIALLY PROCESSED DATA TABLE')\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6af4f-1b2c-4141-bcba-8cde3bfd0964",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>3. Creating a word index</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b549a9f-9115-47a1-9975-eff4864d004b",
   "metadata": {},
   "source": [
    "### 3.1 Creating and filtering words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d392bfde-748a-440c-91b0-47de7335753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MOST COMMON WORDS IN THE DATASET:\n",
      "o :  19637\n",
      "produto :  18851\n",
      "e :  16376\n",
      "a :  12730\n",
      "de :  11778\n",
      "do :  11392\n",
      "não :  11311\n",
      "que :  8760\n",
      "prazo :  8528\n",
      "muito :  8045\n",
      "\n",
      "Number of actual words in vocabulary: 3476\n"
     ]
    }
   ],
   "source": [
    "#Get all words from reviews\n",
    "all_words = ' '.join(df_model['review_comment_message'].astype(str)).lower()\n",
    "\n",
    "#Clean up the words by removing special characters\n",
    "translation_table = str.maketrans({\n",
    "    ',': ' ',\n",
    "    '.': ' ',\n",
    "    '(': ' ',\n",
    "    ')': ' ',\n",
    "    ':': ' ',\n",
    "    \"/\": ' ',\n",
    "    \"!\": ' ',\n",
    "    \"?\": ' '})\n",
    "\n",
    "words_list = all_words.translate(translation_table).strip().split()\n",
    "\n",
    "#Calculate word counts\n",
    "word_counts = {}\n",
    "\n",
    "for word in words_list:\n",
    "    if word in word_counts:\n",
    "        word_counts[word] += 1\n",
    "    else:\n",
    "        word_counts[word] = 1\n",
    "\n",
    "#Filter off rarely used words\n",
    "cutoff = 5\n",
    "word_counts = {k: v for k, v in sorted(word_counts.items(), key=lambda item: item[1], reverse=True) if v > cutoff}\n",
    "\n",
    "#Check the current state of the index\n",
    "print('\\nMOST COMMON WORDS IN THE DATASET:')\n",
    "i = 0\n",
    "for k, v in word_counts.items():\n",
    "        i += 1\n",
    "        print(k, \": \", v)\n",
    "        if i >= 10:\n",
    "            break\n",
    "\n",
    "print(f'\\nNumber of actual words in vocabulary: {len(word_counts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbc124-673c-4d48-9083-0ef7699cf747",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 Creating the final word index for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c908512-ed5c-4608-9c9a-dd9d62d79472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIRST FEW TOKENS IN VOCABULARY:\n",
      "<PAD> :  0\n",
      "<START> :  1\n",
      "<UNK> :  2\n",
      "o :  3\n",
      "produto :  4\n",
      "e :  5\n",
      "a :  6\n",
      "de :  7\n",
      "do :  8\n",
      "não :  9\n",
      "que :  10\n",
      "\n",
      "Final number of elements in vocabulary: 3479\n"
     ]
    }
   ],
   "source": [
    "#Modify the word list so it can be used by the model\n",
    "word_index = {k: (v+3) for v, k in enumerate(word_counts.keys())}\n",
    "word_index = {'<PAD>': 0, '<START>': 1, '<UNK>': 2, **word_index}\n",
    "word_index = dict(list(word_index.items()))\n",
    "\n",
    "#Check the number of elements in index\n",
    "vocab_n = len(word_index)\n",
    "\n",
    "#Check the final state of the index\n",
    "print('\\nFIRST FEW TOKENS IN VOCABULARY:')\n",
    "\n",
    "for k, v in word_index.items():\n",
    "    print(k, \": \", v)\n",
    "    if v >= 10:\n",
    "        break\n",
    "        \n",
    "print(f'\\nFinal number of elements in vocabulary: {vocab_n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e573a7-84d7-4c44-a29b-b7cf2600c838",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>4. Tokenization</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25417e8a-3393-4d32-96a1-33d38845bb90",
   "metadata": {},
   "source": [
    "### 4.1 Creating functions to encode and decode reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6482c575-7f2f-439f-bec8-8d42e92f2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create review encoding function\n",
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "    for word in s.split():\n",
    "        word = word.translate(translation_table).strip().lower()\n",
    "        if word in word_index:\n",
    "            encoded.append(word_index[word])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "\n",
    "    return encoded\n",
    "\n",
    "#Create review decoding function\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def review_decode(s):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854974c-e41e-4913-91c0-e6e60b829639",
   "metadata": {},
   "source": [
    "### 4.2 Tokenizing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc237461-3c31-4e9c-b871-195dbd1bafa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENCODED REVIEWS TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 17, 30, 15, 8, 11, 227]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 77, 163, 62, 96, 80, 109, 457, 670, 5, 648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 436, 362, 18, 65, 6, 388, 8, 436, 135, 245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 31, 22, 143, 2, 170, 767, 61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 132, 395, 4, 99, 5, 13, 15, 8, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_score                             review_comment_message\n",
       "3              2                        [1, 17, 30, 15, 8, 11, 227]\n",
       "4              2  [1, 77, 163, 62, 96, 80, 109, 457, 670, 5, 648...\n",
       "9              2  [1, 436, 362, 18, 65, 6, 388, 8, 436, 135, 245...\n",
       "12             2                  [1, 31, 22, 143, 2, 170, 767, 61]\n",
       "15             2             [1, 132, 395, 4, 99, 5, 13, 15, 8, 11]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode reviews\n",
    "df_model['review_comment_message'] = df_model['review_comment_message'].apply(review_encode)\n",
    "\n",
    "print('\\nENCODED REVIEWS TABLE')\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc43a3b-dcca-4ebf-8dc7-1962c26ad650",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>5. Model creation</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab484b2-ac1b-4e60-b257-d8cc37467e6f",
   "metadata": {},
   "source": [
    "### 5.1 Creating test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fedc29bc-abdc-4572-9b28-ebb6e97120d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum comment length: 46\n"
     ]
    }
   ],
   "source": [
    "#Set up train test split\n",
    "X = df_model['review_comment_message']\n",
    "y = df_model['review_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Check the maximum comment length to decide on maxlen argument for padding\n",
    "print(f'\\nMaximum comment length: {df_model[\"review_comment_message\"].apply(len).max()}')\n",
    "\n",
    "#Pad train and test sequences\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train, value=word_index['<PAD>'], padding='post', maxlen=50)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test, value=word_index['<PAD>'], padding='post', maxlen=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa71745-9442-4571-ab90-b8504eac556d",
   "metadata": {},
   "source": [
    "### 5.2 Building or loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ee3a6a-26f5-4792-89f8-843942e0c05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Create the model\\nmodel = keras.Sequential()\\nmodel.add(keras.layers.Embedding(vocab_n, 16))\\nmodel.add(keras.layers.GlobalAveragePooling1D())\\nmodel.add(keras.layers.Dense(16, activation=\\'relu\\'))\\nmodel.add(keras.layers.Dense(16, activation=\\'relu\\'))\\nmodel.add(keras.layers.Dense(3, activation=\\'softmax\\'))\\n\\nmodel.compile(optimizer=\\'adam\\', loss=\\'sparse_categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n#Train the model\\nfit_model = model.fit(X_train, y_train, epochs=200, batch_size=512, validation_data=(X_test, y_test), verbose=1)\\n\\n#Save the model\\nmodel.save(\"model_reviews.keras\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model\n",
    "model = keras.models.load_model(\"model_reviews.keras\")\n",
    "\n",
    "'''\n",
    "#Create the model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_n, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "fit_model = model.fit(X_train, y_train, epochs=200, batch_size=512, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "#Save the model\n",
    "model.save(\"model_reviews.keras\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65013aa-78fb-47ce-aa16-c9342810d1b4",
   "metadata": {},
   "source": [
    "### 5.3 Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "550730d8-ac92-4a9c-a791-f22380b34ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,664</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │          \u001b[38;5;34m55,664\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,779</span> (659.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m168,779\u001b[0m (659.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,259</span> (219.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,259\u001b[0m (219.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,520</span> (439.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m112,520\u001b[0m (439.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8126 - loss: 0.9488\n",
      "\n",
      "Accuracy: 0.8179858922958374, Loss: 0.9397571682929993\n"
     ]
    }
   ],
   "source": [
    "#Model assessment\n",
    "model.summary()\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(f'\\nAccuracy: {results[1]}, Loss: {results[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64919498-dc98-4f74-9003-0f178726a24a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <u>6. User input prediction</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b158eb5-5bfa-424e-b434-80c2e27cfd09",
   "metadata": {},
   "source": [
    "### 6.1 Create appropriate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786e19b8-ee29-48c7-a98c-f2c7663e0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a comment prediction function\n",
    "def predict_comment(comment):\n",
    "    comment_encoded = keras.preprocessing.sequence.pad_sequences([review_encode(comment)], value=word_index[\"<PAD>\"], padding=\"post\", maxlen=50)\n",
    "    predictions = model.predict(comment_encoded)\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        class_labels = [\"Bad\", \"Neutral\", \"Good\"]\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "        \n",
    "        print(f'Comment: {comment}\\n')\n",
    "        print(f'Bad comment chance:     {prediction[0] * 100:.2f}%')\n",
    "        print(f'Neutral comment chance: {prediction[1] * 100:.2f}%')\n",
    "        print(f'Good comment chance:    {prediction[2] * 100:.2f}%\\n')\n",
    "        print(f\"FINAL PREDICTION:       {predicted_label} comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c60b46-c722-4acf-92c7-31960255b035",
   "metadata": {},
   "source": [
    "### 6.2 Comment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc61ba74-5354-4670-b6d4-95a0c295a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Comment: Compra ruim, não estou satisfeito.\n",
      "\n",
      "Bad comment chance:     96.04%\n",
      "Neutral comment chance: 2.35%\n",
      "Good comment chance:    1.61%\n",
      "\n",
      "FINAL PREDICTION:       Bad comment\n"
     ]
    }
   ],
   "source": [
    "#Input your comment as the argument to check model's prediction\n",
    "predict_comment(\"Compra ruim, não estou satisfeito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
