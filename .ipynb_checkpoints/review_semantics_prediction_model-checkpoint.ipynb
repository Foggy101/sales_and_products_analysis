{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d310f01-8cdf-4865-8ca0-aca1ceb11ebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANALYSIS OF REVIEW SEMANTICS (<u>PREDICTION MODEL</u>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696b2b9d-6525-4b69-b33d-1fc76c4faeed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>1. Preliminaries</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f5892-7aa5-4e2e-9c46-aab970996715",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9deeaea1-af4f-4283-831f-50055ef47f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\PROGRAMOWANIE\\anaconda\\program\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "G:\\PROGRAMOWANIE\\anaconda\\program\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Import necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5c28c-fdc4-4def-bfe3-f9cd75256af7",
   "metadata": {},
   "source": [
    "### 1.2 Version check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7e77be-da65-44bc-9365-5b8c2aa8ca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "Keras version: 3.3.3\n",
      "NumPy version: 1.26.4\n",
      "Pandas version: 2.2.2\n",
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "#Check Python version\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'Keras version: {keras.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65aa6d-1d01-40dc-919d-ff1627196437",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>2. Data preperation</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd5385c-ceea-4f48-863a-df3b13545c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALLY PROCESSED DATA TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Parabéns lojas lannister adorei comprar pela I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_score                             review_comment_message\n",
       "3              2              Recebi bem antes do prazo estipulado.\n",
       "4              2  Parabéns lojas lannister adorei comprar pela I...\n",
       "9              2  aparelho eficiente. no site a marca do aparelh...\n",
       "12             2    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "15             2  Vendedor confiável, produto ok e entrega antes..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data\n",
    "df = pd.read_csv(\"order_reviews.csv\")\n",
    "\n",
    "#Modify the original dataframe\n",
    "df_model = df.drop(['review_id', 'order_id', 'review_comment_title', 'review_creation_date', 'review_answer_timestamp'], axis=1).dropna()\n",
    "\n",
    "#Define and apply score mapping: 0 - bad, 1 - neutral, 2 - good\n",
    "score_mapping = {1: 0,\n",
    "                 2: 0,\n",
    "                 3: 1,\n",
    "                 4: 2,\n",
    "                 5: 2}\n",
    "\n",
    "df_model['review_score'] = df_model['review_score'].map(score_mapping)\n",
    "\n",
    "print('\\nINITIALLY PROCESSED DATA TABLE')\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6af4f-1b2c-4141-bcba-8cde3bfd0964",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>3. Creating a word index</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b549a9f-9115-47a1-9975-eff4864d004b",
   "metadata": {},
   "source": [
    "### 3.1 Creating and filtering words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d392bfde-748a-440c-91b0-47de7335753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MOST COMMON WORDS IN THE DATASET:\n",
      "o :  19637\n",
      "produto :  18851\n",
      "e :  16376\n",
      "a :  12730\n",
      "de :  11778\n",
      "do :  11392\n",
      "não :  11311\n",
      "que :  8760\n",
      "prazo :  8528\n",
      "muito :  8045\n",
      "\n",
      "Number of actual words in vocabulary: 3476\n"
     ]
    }
   ],
   "source": [
    "#Get all words from reviews\n",
    "all_words = ' '.join(df_model['review_comment_message'].astype(str)).lower()\n",
    "\n",
    "#Clean up the words by removing special characters\n",
    "translation_table = str.maketrans({\n",
    "    ',': ' ',\n",
    "    '.': ' ',\n",
    "    '(': ' ',\n",
    "    ')': ' ',\n",
    "    ':': ' ',\n",
    "    \"/\": ' ',\n",
    "    \"!\": ' ',\n",
    "    \"?\": ' '})\n",
    "\n",
    "words_list = all_words.translate(translation_table).strip().split()\n",
    "\n",
    "#Calculate word counts\n",
    "word_counts = {}\n",
    "\n",
    "for word in words_list:\n",
    "    if word in word_counts:\n",
    "        word_counts[word] += 1\n",
    "    else:\n",
    "        word_counts[word] = 1\n",
    "\n",
    "#Filter off rarely used words\n",
    "cutoff = 5\n",
    "word_counts = {k: v for k, v in sorted(word_counts.items(), key=lambda item: item[1], reverse=True) if v > cutoff}\n",
    "\n",
    "#Check the current state of the index\n",
    "print('\\nMOST COMMON WORDS IN THE DATASET:')\n",
    "i = 0\n",
    "for k, v in word_counts.items():\n",
    "        i += 1\n",
    "        print(k, \": \", v)\n",
    "        if i >= 10:\n",
    "            break\n",
    "\n",
    "print(f'\\nNumber of actual words in vocabulary: {len(word_counts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbc124-673c-4d48-9083-0ef7699cf747",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 Creating the final word index for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c908512-ed5c-4608-9c9a-dd9d62d79472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIRST FEW TOKENS IN VOCABULARY:\n",
      "<PAD> :  0\n",
      "<START> :  1\n",
      "<UNK> :  2\n",
      "o :  3\n",
      "produto :  4\n",
      "e :  5\n",
      "a :  6\n",
      "de :  7\n",
      "do :  8\n",
      "não :  9\n",
      "que :  10\n",
      "\n",
      "Final number of elements in vocabulary: 3479\n"
     ]
    }
   ],
   "source": [
    "#Modify the word list so it can be used by the model\n",
    "word_index = {k: (v+3) for v, k in enumerate(word_counts.keys())}\n",
    "word_index = {'<PAD>': 0, '<START>': 1, '<UNK>': 2, **word_index}\n",
    "word_index = dict(list(word_index.items()))\n",
    "\n",
    "#Check the number of elements in index\n",
    "vocab_n = len(word_index)\n",
    "\n",
    "#Check the final state of the index\n",
    "print('\\nFIRST FEW TOKENS IN VOCABULARY:')\n",
    "\n",
    "for k, v in word_index.items():\n",
    "    print(k, \": \", v)\n",
    "    if v >= 10:\n",
    "        break\n",
    "        \n",
    "print(f'\\nFinal number of elements in vocabulary: {vocab_n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e573a7-84d7-4c44-a29b-b7cf2600c838",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>4. Tokenization</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25417e8a-3393-4d32-96a1-33d38845bb90",
   "metadata": {},
   "source": [
    "### 4.1 Creating functions to encode and decode reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6482c575-7f2f-439f-bec8-8d42e92f2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create review encoding function\n",
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "    for word in s.split():\n",
    "        word = word.translate(translation_table).strip().lower()\n",
    "        if word in word_index:\n",
    "            encoded.append(word_index[word])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "\n",
    "    return encoded\n",
    "\n",
    "#Create review decoding function\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def review_decode(s):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854974c-e41e-4913-91c0-e6e60b829639",
   "metadata": {},
   "source": [
    "### 4.2 Tokenizing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc237461-3c31-4e9c-b871-195dbd1bafa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENCODED REVIEWS TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_comment_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 17, 30, 15, 8, 11, 227]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 77, 163, 62, 96, 80, 109, 457, 670, 5, 648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 436, 362, 18, 65, 6, 388, 8, 436, 135, 245...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 31, 22, 143, 2, 170, 767, 61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 132, 395, 4, 99, 5, 13, 15, 8, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_score                             review_comment_message\n",
       "3              2                        [1, 17, 30, 15, 8, 11, 227]\n",
       "4              2  [1, 77, 163, 62, 96, 80, 109, 457, 670, 5, 648...\n",
       "9              2  [1, 436, 362, 18, 65, 6, 388, 8, 436, 135, 245...\n",
       "12             2                  [1, 31, 22, 143, 2, 170, 767, 61]\n",
       "15             2             [1, 132, 395, 4, 99, 5, 13, 15, 8, 11]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode reviews\n",
    "df_model['review_comment_message'] = df_model['review_comment_message'].apply(review_encode)\n",
    "\n",
    "print('\\nENCODED REVIEWS TABLE')\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc43a3b-dcca-4ebf-8dc7-1962c26ad650",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <u>5. Model creation</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab484b2-ac1b-4e60-b257-d8cc37467e6f",
   "metadata": {},
   "source": [
    "### 5.1 Creating test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fedc29bc-abdc-4572-9b28-ebb6e97120d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum comment length: 46\n"
     ]
    }
   ],
   "source": [
    "#Set up train test split\n",
    "X = df_model['review_comment_message']\n",
    "y = df_model['review_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Check the maximum comment length to decide on maxlen argument for padding\n",
    "print(f'\\nMaximum comment length: {df_model[\"review_comment_message\"].apply(len).max()}')\n",
    "\n",
    "#Pad train and test sequences\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train, value=word_index['<PAD>'], padding='post', maxlen=50)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test, value=word_index['<PAD>'], padding='post', maxlen=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa71745-9442-4571-ab90-b8504eac556d",
   "metadata": {},
   "source": [
    "### 5.2 Building or loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7ee3a6a-26f5-4792-89f8-843942e0c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6150 - loss: 0.9152 - val_accuracy: 0.6349 - val_loss: 0.7997\n",
      "Epoch 2/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.7816 - val_accuracy: 0.6967 - val_loss: 0.7290\n",
      "Epoch 3/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7143 - loss: 0.7037 - val_accuracy: 0.7694 - val_loss: 0.6224\n",
      "Epoch 4/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7721 - loss: 0.6014 - val_accuracy: 0.8090 - val_loss: 0.5493\n",
      "Epoch 5/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8037 - loss: 0.5412 - val_accuracy: 0.8176 - val_loss: 0.5142\n",
      "Epoch 6/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.5044 - val_accuracy: 0.8239 - val_loss: 0.4974\n",
      "Epoch 7/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4842 - val_accuracy: 0.8268 - val_loss: 0.4846\n",
      "Epoch 8/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.4748 - val_accuracy: 0.8333 - val_loss: 0.4753\n",
      "Epoch 9/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8372 - loss: 0.4602 - val_accuracy: 0.8379 - val_loss: 0.4681\n",
      "Epoch 10/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.4530 - val_accuracy: 0.8410 - val_loss: 0.4658\n",
      "Epoch 11/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.4539 - val_accuracy: 0.8417 - val_loss: 0.4552\n",
      "Epoch 12/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.4363 - val_accuracy: 0.8434 - val_loss: 0.4516\n",
      "Epoch 13/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.4373 - val_accuracy: 0.8446 - val_loss: 0.4543\n",
      "Epoch 14/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.4376 - val_accuracy: 0.8455 - val_loss: 0.4440\n",
      "Epoch 15/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.4307 - val_accuracy: 0.8471 - val_loss: 0.4418\n",
      "Epoch 16/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8534 - loss: 0.4215 - val_accuracy: 0.8353 - val_loss: 0.4590\n",
      "Epoch 17/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.4161 - val_accuracy: 0.8492 - val_loss: 0.4387\n",
      "Epoch 18/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.4159 - val_accuracy: 0.8471 - val_loss: 0.4378\n",
      "Epoch 19/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.4119 - val_accuracy: 0.8495 - val_loss: 0.4376\n",
      "Epoch 20/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.4100 - val_accuracy: 0.8456 - val_loss: 0.4390\n",
      "Epoch 21/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.4056 - val_accuracy: 0.8483 - val_loss: 0.4337\n",
      "Epoch 22/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.4046 - val_accuracy: 0.8494 - val_loss: 0.4333\n",
      "Epoch 23/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.4058 - val_accuracy: 0.8464 - val_loss: 0.4367\n",
      "Epoch 24/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8628 - loss: 0.3972 - val_accuracy: 0.8470 - val_loss: 0.4325\n",
      "Epoch 25/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8624 - loss: 0.3962 - val_accuracy: 0.8488 - val_loss: 0.4342\n",
      "Epoch 26/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.3885 - val_accuracy: 0.8490 - val_loss: 0.4344\n",
      "Epoch 27/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.3889 - val_accuracy: 0.8471 - val_loss: 0.4307\n",
      "Epoch 28/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3865 - val_accuracy: 0.8479 - val_loss: 0.4307\n",
      "Epoch 29/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8663 - loss: 0.3802 - val_accuracy: 0.8473 - val_loss: 0.4307\n",
      "Epoch 30/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3839 - val_accuracy: 0.8464 - val_loss: 0.4309\n",
      "Epoch 31/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3826 - val_accuracy: 0.8470 - val_loss: 0.4367\n",
      "Epoch 32/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3772 - val_accuracy: 0.8489 - val_loss: 0.4318\n",
      "Epoch 33/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.3756 - val_accuracy: 0.8468 - val_loss: 0.4330\n",
      "Epoch 34/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.3703 - val_accuracy: 0.8473 - val_loss: 0.4328\n",
      "Epoch 35/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8691 - loss: 0.3671 - val_accuracy: 0.8489 - val_loss: 0.4310\n",
      "Epoch 36/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.3765 - val_accuracy: 0.8434 - val_loss: 0.4481\n",
      "Epoch 37/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.3723 - val_accuracy: 0.8485 - val_loss: 0.4323\n",
      "Epoch 38/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3677 - val_accuracy: 0.8466 - val_loss: 0.4349\n",
      "Epoch 39/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.3638 - val_accuracy: 0.8494 - val_loss: 0.4338\n",
      "Epoch 40/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.3685 - val_accuracy: 0.8476 - val_loss: 0.4378\n",
      "Epoch 41/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3610 - val_accuracy: 0.8465 - val_loss: 0.4423\n",
      "Epoch 42/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.3585 - val_accuracy: 0.8440 - val_loss: 0.4438\n",
      "Epoch 43/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8752 - loss: 0.3540 - val_accuracy: 0.8470 - val_loss: 0.4381\n",
      "Epoch 44/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3523 - val_accuracy: 0.8484 - val_loss: 0.4481\n",
      "Epoch 45/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8746 - loss: 0.3486 - val_accuracy: 0.8476 - val_loss: 0.4425\n",
      "Epoch 46/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3490 - val_accuracy: 0.8433 - val_loss: 0.4497\n",
      "Epoch 47/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.3447 - val_accuracy: 0.8405 - val_loss: 0.4484\n",
      "Epoch 48/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.3531 - val_accuracy: 0.8423 - val_loss: 0.4444\n",
      "Epoch 49/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.3517 - val_accuracy: 0.8439 - val_loss: 0.4450\n",
      "Epoch 50/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.3456 - val_accuracy: 0.8412 - val_loss: 0.4575\n",
      "Epoch 51/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8777 - loss: 0.3421 - val_accuracy: 0.8430 - val_loss: 0.4478\n",
      "Epoch 52/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8780 - loss: 0.3417 - val_accuracy: 0.8434 - val_loss: 0.4646\n",
      "Epoch 53/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.3452 - val_accuracy: 0.8423 - val_loss: 0.4533\n",
      "Epoch 54/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.3413 - val_accuracy: 0.8415 - val_loss: 0.4530\n",
      "Epoch 55/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8805 - loss: 0.3375 - val_accuracy: 0.8405 - val_loss: 0.4570\n",
      "Epoch 56/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.3364 - val_accuracy: 0.8416 - val_loss: 0.4574\n",
      "Epoch 57/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3299 - val_accuracy: 0.8428 - val_loss: 0.4702\n",
      "Epoch 58/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8825 - loss: 0.3305 - val_accuracy: 0.8410 - val_loss: 0.4618\n",
      "Epoch 59/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8817 - loss: 0.3360 - val_accuracy: 0.8416 - val_loss: 0.4659\n",
      "Epoch 60/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8844 - loss: 0.3276 - val_accuracy: 0.8419 - val_loss: 0.4745\n",
      "Epoch 61/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8865 - loss: 0.3213 - val_accuracy: 0.8418 - val_loss: 0.4774\n",
      "Epoch 62/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8837 - loss: 0.3294 - val_accuracy: 0.8393 - val_loss: 0.4726\n",
      "Epoch 63/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8868 - loss: 0.3245 - val_accuracy: 0.8369 - val_loss: 0.4774\n",
      "Epoch 64/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8858 - loss: 0.3227 - val_accuracy: 0.8398 - val_loss: 0.4810\n",
      "Epoch 65/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.3256 - val_accuracy: 0.8401 - val_loss: 0.4877\n",
      "Epoch 66/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8880 - loss: 0.3189 - val_accuracy: 0.8394 - val_loss: 0.4793\n",
      "Epoch 67/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.3212 - val_accuracy: 0.8399 - val_loss: 0.4859\n",
      "Epoch 68/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.3177 - val_accuracy: 0.8383 - val_loss: 0.4817\n",
      "Epoch 69/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.3141 - val_accuracy: 0.8400 - val_loss: 0.4900\n",
      "Epoch 70/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.3176 - val_accuracy: 0.8394 - val_loss: 0.4874\n",
      "Epoch 71/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8909 - loss: 0.3115 - val_accuracy: 0.8381 - val_loss: 0.4902\n",
      "Epoch 72/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.3167 - val_accuracy: 0.8349 - val_loss: 0.4926\n",
      "Epoch 73/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8915 - loss: 0.3157 - val_accuracy: 0.8381 - val_loss: 0.4947\n",
      "Epoch 74/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.3126 - val_accuracy: 0.8394 - val_loss: 0.5006\n",
      "Epoch 75/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8902 - loss: 0.3161 - val_accuracy: 0.8353 - val_loss: 0.4949\n",
      "Epoch 76/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8911 - loss: 0.3134 - val_accuracy: 0.8397 - val_loss: 0.5124\n",
      "Epoch 77/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.3109 - val_accuracy: 0.8363 - val_loss: 0.5004\n",
      "Epoch 78/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.3053 - val_accuracy: 0.8363 - val_loss: 0.5068\n",
      "Epoch 79/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.3130 - val_accuracy: 0.8369 - val_loss: 0.5093\n",
      "Epoch 80/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.3034 - val_accuracy: 0.8371 - val_loss: 0.5170\n",
      "Epoch 81/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8934 - loss: 0.3106 - val_accuracy: 0.8361 - val_loss: 0.5182\n",
      "Epoch 82/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.3031 - val_accuracy: 0.8388 - val_loss: 0.5309\n",
      "Epoch 83/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.3070 - val_accuracy: 0.8343 - val_loss: 0.5234\n",
      "Epoch 84/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3121 - val_accuracy: 0.8351 - val_loss: 0.5251\n",
      "Epoch 85/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.3032 - val_accuracy: 0.8374 - val_loss: 0.5387\n",
      "Epoch 86/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8946 - loss: 0.3060 - val_accuracy: 0.8321 - val_loss: 0.5182\n",
      "Epoch 87/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.3031 - val_accuracy: 0.8302 - val_loss: 0.5295\n",
      "Epoch 88/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8999 - loss: 0.2970 - val_accuracy: 0.8346 - val_loss: 0.5457\n",
      "Epoch 89/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.2978 - val_accuracy: 0.8325 - val_loss: 0.5252\n",
      "Epoch 90/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9009 - loss: 0.2953 - val_accuracy: 0.8351 - val_loss: 0.5434\n",
      "Epoch 91/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 0.3015 - val_accuracy: 0.8358 - val_loss: 0.5496\n",
      "Epoch 92/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.2949 - val_accuracy: 0.8307 - val_loss: 0.5392\n",
      "Epoch 93/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.2919 - val_accuracy: 0.8302 - val_loss: 0.5358\n",
      "Epoch 94/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.2962 - val_accuracy: 0.8295 - val_loss: 0.5461\n",
      "Epoch 95/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.2897 - val_accuracy: 0.8345 - val_loss: 0.5593\n",
      "Epoch 96/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9024 - loss: 0.2899 - val_accuracy: 0.8315 - val_loss: 0.5474\n",
      "Epoch 97/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 0.2948 - val_accuracy: 0.8352 - val_loss: 0.5557\n",
      "Epoch 98/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9067 - loss: 0.2794 - val_accuracy: 0.8352 - val_loss: 0.5668\n",
      "Epoch 99/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.2869 - val_accuracy: 0.8348 - val_loss: 0.5649\n",
      "Epoch 100/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9048 - loss: 0.2880 - val_accuracy: 0.8321 - val_loss: 0.5684\n",
      "Epoch 101/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.2813 - val_accuracy: 0.8300 - val_loss: 0.5582\n",
      "Epoch 102/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9050 - loss: 0.2864 - val_accuracy: 0.8350 - val_loss: 0.5655\n",
      "Epoch 103/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9056 - loss: 0.2857 - val_accuracy: 0.8319 - val_loss: 0.5901\n",
      "Epoch 104/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9057 - loss: 0.2888 - val_accuracy: 0.8318 - val_loss: 0.5761\n",
      "Epoch 105/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.2778 - val_accuracy: 0.8255 - val_loss: 0.5716\n",
      "Epoch 106/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2761 - val_accuracy: 0.8310 - val_loss: 0.5852\n",
      "Epoch 107/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2759 - val_accuracy: 0.8365 - val_loss: 0.5942\n",
      "Epoch 108/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2870 - val_accuracy: 0.8336 - val_loss: 0.5948\n",
      "Epoch 109/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2748 - val_accuracy: 0.8278 - val_loss: 0.5777\n",
      "Epoch 110/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2714 - val_accuracy: 0.8315 - val_loss: 0.5872\n",
      "Epoch 111/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2728 - val_accuracy: 0.8266 - val_loss: 0.5901\n",
      "Epoch 112/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2745 - val_accuracy: 0.8316 - val_loss: 0.5931\n",
      "Epoch 113/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.2782 - val_accuracy: 0.8240 - val_loss: 0.5827\n",
      "Epoch 114/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2692 - val_accuracy: 0.8338 - val_loss: 0.6180\n",
      "Epoch 115/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9127 - loss: 0.2733 - val_accuracy: 0.8321 - val_loss: 0.6053\n",
      "Epoch 116/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2726 - val_accuracy: 0.8260 - val_loss: 0.5966\n",
      "Epoch 117/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2628 - val_accuracy: 0.8325 - val_loss: 0.6194\n",
      "Epoch 118/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.2556 - val_accuracy: 0.8292 - val_loss: 0.6079\n",
      "Epoch 119/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.2561 - val_accuracy: 0.8344 - val_loss: 0.6338\n",
      "Epoch 120/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.2678 - val_accuracy: 0.8322 - val_loss: 0.6333\n",
      "Epoch 121/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2616 - val_accuracy: 0.8303 - val_loss: 0.6229\n",
      "Epoch 122/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2528 - val_accuracy: 0.8306 - val_loss: 0.6357\n",
      "Epoch 123/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2509 - val_accuracy: 0.8259 - val_loss: 0.6272\n",
      "Epoch 124/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2616 - val_accuracy: 0.8268 - val_loss: 0.6545\n",
      "Epoch 125/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9160 - loss: 0.2595 - val_accuracy: 0.8268 - val_loss: 0.6388\n",
      "Epoch 126/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.2587 - val_accuracy: 0.8254 - val_loss: 0.6271\n",
      "Epoch 127/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2502 - val_accuracy: 0.8225 - val_loss: 0.6331\n",
      "Epoch 128/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2576 - val_accuracy: 0.8231 - val_loss: 0.6367\n",
      "Epoch 129/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.2513 - val_accuracy: 0.8235 - val_loss: 0.6402\n",
      "Epoch 130/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2432 - val_accuracy: 0.8277 - val_loss: 0.6602\n",
      "Epoch 131/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.2497 - val_accuracy: 0.8227 - val_loss: 0.6684\n",
      "Epoch 132/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9199 - loss: 0.2525 - val_accuracy: 0.8201 - val_loss: 0.6405\n",
      "Epoch 133/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.2496 - val_accuracy: 0.8301 - val_loss: 0.6882\n",
      "Epoch 134/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9230 - loss: 0.2437 - val_accuracy: 0.8136 - val_loss: 0.6494\n",
      "Epoch 135/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.2523 - val_accuracy: 0.8249 - val_loss: 0.6659\n",
      "Epoch 136/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.2445 - val_accuracy: 0.8260 - val_loss: 0.6803\n",
      "Epoch 137/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.2398 - val_accuracy: 0.8254 - val_loss: 0.6776\n",
      "Epoch 138/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9231 - loss: 0.2429 - val_accuracy: 0.8259 - val_loss: 0.6702\n",
      "Epoch 139/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.2396 - val_accuracy: 0.8236 - val_loss: 0.6786\n",
      "Epoch 140/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.2399 - val_accuracy: 0.8245 - val_loss: 0.6839\n",
      "Epoch 141/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9286 - loss: 0.2342 - val_accuracy: 0.8247 - val_loss: 0.6926\n",
      "Epoch 142/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.2338 - val_accuracy: 0.8223 - val_loss: 0.7016\n",
      "Epoch 143/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9244 - loss: 0.2425 - val_accuracy: 0.8150 - val_loss: 0.7004\n",
      "Epoch 144/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.2297 - val_accuracy: 0.8206 - val_loss: 0.6971\n",
      "Epoch 145/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9286 - loss: 0.2337 - val_accuracy: 0.8245 - val_loss: 0.7152\n",
      "Epoch 146/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9295 - loss: 0.2311 - val_accuracy: 0.8230 - val_loss: 0.7198\n",
      "Epoch 147/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.2367 - val_accuracy: 0.8276 - val_loss: 0.7221\n",
      "Epoch 148/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9306 - loss: 0.2299 - val_accuracy: 0.8246 - val_loss: 0.7215\n",
      "Epoch 149/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.2314 - val_accuracy: 0.8278 - val_loss: 0.7468\n",
      "Epoch 150/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.2307 - val_accuracy: 0.8258 - val_loss: 0.7359\n",
      "Epoch 151/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.2276 - val_accuracy: 0.8199 - val_loss: 0.7074\n",
      "Epoch 152/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.2274 - val_accuracy: 0.8231 - val_loss: 0.7263\n",
      "Epoch 153/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.2255 - val_accuracy: 0.8236 - val_loss: 0.7388\n",
      "Epoch 154/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.2261 - val_accuracy: 0.8194 - val_loss: 0.7347\n",
      "Epoch 155/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9328 - loss: 0.2211 - val_accuracy: 0.8203 - val_loss: 0.7584\n",
      "Epoch 156/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.2184 - val_accuracy: 0.8173 - val_loss: 0.7569\n",
      "Epoch 157/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.2235 - val_accuracy: 0.8197 - val_loss: 0.7434\n",
      "Epoch 158/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.2259 - val_accuracy: 0.8169 - val_loss: 0.7446\n",
      "Epoch 159/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9287 - loss: 0.2311 - val_accuracy: 0.8240 - val_loss: 0.7590\n",
      "Epoch 160/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.2261 - val_accuracy: 0.8262 - val_loss: 0.7540\n",
      "Epoch 161/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.2147 - val_accuracy: 0.8236 - val_loss: 0.7561\n",
      "Epoch 162/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.2185 - val_accuracy: 0.8259 - val_loss: 0.7828\n",
      "Epoch 163/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9310 - loss: 0.2208 - val_accuracy: 0.8200 - val_loss: 0.7729\n",
      "Epoch 164/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.2159 - val_accuracy: 0.8233 - val_loss: 0.7630\n",
      "Epoch 165/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9353 - loss: 0.2134 - val_accuracy: 0.8207 - val_loss: 0.7591\n",
      "Epoch 166/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.2171 - val_accuracy: 0.8155 - val_loss: 0.7990\n",
      "Epoch 167/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2188 - val_accuracy: 0.8188 - val_loss: 0.8015\n",
      "Epoch 168/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.2131 - val_accuracy: 0.8211 - val_loss: 0.7749\n",
      "Epoch 169/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9361 - loss: 0.2136 - val_accuracy: 0.8198 - val_loss: 0.8025\n",
      "Epoch 170/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.2120 - val_accuracy: 0.8160 - val_loss: 0.7774\n",
      "Epoch 171/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.2206 - val_accuracy: 0.8222 - val_loss: 0.7983\n",
      "Epoch 172/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.2118 - val_accuracy: 0.8197 - val_loss: 0.8071\n",
      "Epoch 173/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.2117 - val_accuracy: 0.8189 - val_loss: 0.8036\n",
      "Epoch 174/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9365 - loss: 0.2131 - val_accuracy: 0.8125 - val_loss: 0.8128\n",
      "Epoch 175/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.2208 - val_accuracy: 0.8195 - val_loss: 0.8140\n",
      "Epoch 176/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.2116 - val_accuracy: 0.8164 - val_loss: 0.8337\n",
      "Epoch 177/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.2021 - val_accuracy: 0.8094 - val_loss: 0.8395\n",
      "Epoch 178/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.2118 - val_accuracy: 0.8211 - val_loss: 0.8459\n",
      "Epoch 179/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.2029 - val_accuracy: 0.8206 - val_loss: 0.8562\n",
      "Epoch 180/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.2078 - val_accuracy: 0.8203 - val_loss: 0.8274\n",
      "Epoch 181/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.2019 - val_accuracy: 0.8148 - val_loss: 0.8392\n",
      "Epoch 182/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9378 - loss: 0.2094 - val_accuracy: 0.8150 - val_loss: 0.8396\n",
      "Epoch 183/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 0.2059 - val_accuracy: 0.8067 - val_loss: 0.8980\n",
      "Epoch 184/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9371 - loss: 0.2112 - val_accuracy: 0.8185 - val_loss: 0.8721\n",
      "Epoch 185/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9390 - loss: 0.2061 - val_accuracy: 0.8193 - val_loss: 0.8649\n",
      "Epoch 186/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9392 - loss: 0.2027 - val_accuracy: 0.8148 - val_loss: 0.8681\n",
      "Epoch 187/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 0.2048 - val_accuracy: 0.8192 - val_loss: 0.8762\n",
      "Epoch 188/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.1994 - val_accuracy: 0.8177 - val_loss: 0.9149\n",
      "Epoch 189/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.1984 - val_accuracy: 0.8158 - val_loss: 0.9097\n",
      "Epoch 190/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.2016 - val_accuracy: 0.8170 - val_loss: 0.9017\n",
      "Epoch 191/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9427 - loss: 0.2019 - val_accuracy: 0.8222 - val_loss: 0.9371\n",
      "Epoch 192/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9427 - loss: 0.1957 - val_accuracy: 0.8189 - val_loss: 0.9081\n",
      "Epoch 193/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9404 - loss: 0.2016 - val_accuracy: 0.8120 - val_loss: 0.9008\n",
      "Epoch 194/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9392 - loss: 0.2018 - val_accuracy: 0.8187 - val_loss: 0.9303\n",
      "Epoch 195/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1919 - val_accuracy: 0.8132 - val_loss: 0.9071\n",
      "Epoch 196/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9412 - loss: 0.1968 - val_accuracy: 0.8193 - val_loss: 0.9325\n",
      "Epoch 197/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9398 - loss: 0.2007 - val_accuracy: 0.8213 - val_loss: 0.9293\n",
      "Epoch 198/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9435 - loss: 0.1913 - val_accuracy: 0.8133 - val_loss: 0.9463\n",
      "Epoch 199/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9459 - loss: 0.1889 - val_accuracy: 0.8078 - val_loss: 0.9280\n",
      "Epoch 200/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9427 - loss: 0.1963 - val_accuracy: 0.8180 - val_loss: 0.9398\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "model = keras.models.load_model(\"model_reviews.keras\")\n",
    "\n",
    "'''\n",
    "#Create the model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_n, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "fit_model = model.fit(X_train, y_train, epochs=200, batch_size=512, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "#Save the model\n",
    "model.save(\"model_reviews.keras\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65013aa-78fb-47ce-aa16-c9342810d1b4",
   "metadata": {},
   "source": [
    "### 5.3 Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "550730d8-ac92-4a9c-a791-f22380b34ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">55,664</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │          \u001b[38;5;34m55,664\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m272\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,779</span> (659.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m168,779\u001b[0m (659.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">56,259</span> (219.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m56,259\u001b[0m (219.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,520</span> (439.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m112,520\u001b[0m (439.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8126 - loss: 0.9488\n",
      "\n",
      "Accuracy: 0.8179858922958374, Loss: 0.9397571682929993\n"
     ]
    }
   ],
   "source": [
    "#Model assessment\n",
    "model.summary()\n",
    "results = model.evaluate(X_test, y_test)\n",
    "print(f'\\nAccuracy: {results[1]}, Loss: {results[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64919498-dc98-4f74-9003-0f178726a24a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <u>6. User input prediction</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b158eb5-5bfa-424e-b434-80c2e27cfd09",
   "metadata": {},
   "source": [
    "### 6.1 Create appropriate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786e19b8-ee29-48c7-a98c-f2c7663e0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a comment prediction function\n",
    "def predict_comment(comment):\n",
    "    comment_encoded = keras.preprocessing.sequence.pad_sequences([review_encode(comment)], value=word_index[\"<PAD>\"], padding=\"post\", maxlen=50)\n",
    "    predictions = model.predict(comment_encoded)\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        predicted_class = np.argmax(prediction)\n",
    "        class_labels = [\"Bad\", \"Neutral\", \"Good\"]\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "        \n",
    "        print(f'Comment: {comment}\\n')\n",
    "        print(f'Bad comment chance:     {prediction[0] * 100:.2f}%')\n",
    "        print(f'Neutral comment chance: {prediction[1] * 100:.2f}%')\n",
    "        print(f'Good comment chance:    {prediction[2] * 100:.2f}%\\n')\n",
    "        print(f\"FINAL PREDICTION:       {predicted_label} comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c60b46-c722-4acf-92c7-31960255b035",
   "metadata": {},
   "source": [
    "### 6.2 Comment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc61ba74-5354-4670-b6d4-95a0c295a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839ms/step\n",
      "Comment: Compra ruim, não estou satisfeito.\n",
      "\n",
      "Bad comment chance:     96.04%\n",
      "Neutral comment chance: 2.35%\n",
      "Good comment chance:    1.61%\n",
      "\n",
      "FINAL PREDICTION:       Bad comment\n"
     ]
    }
   ],
   "source": [
    "#Input your comment as the argument to check model's prediction\n",
    "predict_comment(\"Compra ruim, não estou satisfeito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
